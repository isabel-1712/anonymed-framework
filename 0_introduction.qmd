# Introduction

This framework provides guidance for developing and auditing the models within the ANONY-MED toolbox. The framework thus accompanies the development of models within the ANONY-MED project. 
The overall objective of the ANONY-MED project is the creation of a methodological toolbox for privacy-preserving healthcare AI model development , for use with medical data. Specifically, the toolbox provides two methods: 1) anonymization of raw data through privacy-preserving data synthesis with generative AI methods, and 2) anonymization of result data after data protection-compliant data analysis, through homomorphic encryption (HE). While data generated with 1) is particularly suitable for training AI models for diagnostics, the use of HE is recommended if anonymization of the data would impair the accuracy of the analyses. Both types of anonymization can be evaluated quantitatively in terms of their utility: On the basis of the precision of the predictions of the resulting AI models and the statistical analyses. At the same time, privacy metrics can be used to quantify the degree of anonymization.

In this framework, we would like to provide the toolbox users with programmatic guidance that extends beyond simple utility measures. The framework will enable users to identify and to tackle ethical considerations when developing AI models using the toolbox. The ANONY-MED project proposes three different use cases: for stroke, cardiology, and radiology. On one hand, this framework will serve as a resource for the developers of each of the use cases within the project to test the frameworkâ€™s usefulness and relevance, and for the ethics team to audit the project results. At a later stage, based on the feedback and project results, the framework will be adapted and updated, and will be provided publicly with the toolbox as a resource for end users.

The framework considers general ethical challenges when developing medical AI but also considers specific challenges posed by the methods employed in the project, namely generative AI, homomorphic encryption (HE), and differential privacy. We also place a particular emphasis on considerations about privacy when using these methods for anonymization ofhealth data for data-sharing or for training AI models.

Given the scope of the ANONY-MED project, the presented framework will focus exclusively on the EU region, with its legislative prerequisites, such as the GDPR. The framework also assumes that the toolbox is used in a research setting. 
